# IMDB(영화 리뷰 관련 자료 데이터베이스) : 긍정/부정 5:5
from tensorflow.keras.datasets import imdb

(train_data, train_label), (test_data, test_label) = imdb.load_data(num_words=10000)

print(train_data)
print(train_label)

aa = []
for seq in train_data:
    #print(max(seq))
    aa.append(max(seq))
print(max(aa), len(aa)) # 9999 25000

word_index = imdb.get_word_index() # word_index는 단어와 정수 인덱스를 매핑한 dict type이다.
reverse_word_index = dict([(value, key) for (key ,value) in word_index.items()])
print(reverse_word_index)
decord_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])
print(decord_review)

# list type의 자료를 Tensor로 변환. One-hot encoding
import numpy as np

def vector_seq(sequences, dim = 10000):
    results = np.zeros((len(sequences), dim))
    for i, seq in enumerate(sequences):
        results[i, seq] = 1
    return results
x_train = vector_seq(train_data)
x_test = vector_seq(test_data)

print(train_data[:1])
print(x_train[:1], ' ', x_train.shape) # (25000, 10000)
y_train = train_label
y_test = test_label

print()
# Model
from tensorflow.keras import models
from tensorflow.keras import layers

model = models.Sequential()
model.add(layers.Dense(32, activation = 'relu', input_shape = (10000, )))
model.add(layers.Dense(16, activation = 'relu'))
model.add(layers.Dense(1, activation = 'sigmoid'))

model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])
print(model.summary())

x_val = x_train[:10000]
partial_x_train = x_train[10000:] # 25000개중 10000개
print(len(x_val), len(partial_x_train)) # 10000 15000
y_val = y_train[:10000]
partial_y_train = y_train[10000:]

history = model.fit(partial_x_train, partial_y_train, validation_data=(x_val, y_val), epochs = 10, batch_size = 512)

print('evaluate L ', model.evaluate(x_test, y_test))

print('predict(예측값) : ', model.predict(x_test[:5]))
print('predict(예측값) : ', np.where(model.predict(x_test[:5]) > 0.5, 1, 0).flatten())

# 시각화
history_dict = history.history

import matplotlib.pyplot as plt

acc = history_dict['accuracy']
val_acc = history_dict['val_accuracy']
loss = history_dict['loss']
val_loss = history_dict['val_loss']

epochs = range(1, len(acc) + 1)

# "bo"는 "파란색 점"입니다
plt.plot(epochs, loss, 'bo', label='Training loss')
# b는 "파란 실선"입니다
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

plt.clf()   # 그림을 초기화합니다

plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.show()









