import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.metrics import roc_curve, auc
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.wrappers.scikit_learn import KerasClassifier
from tensorflow.keras.utils import to_categorical
import pandas as pd

df = pd.read_csv('https://raw.githubusercontent.com/pykwon/python/master/testdata_utf8/bmi.csv')
print(df.head(5))
print(df.info())
data = df.values
x = np.array(data[:, 0:-1], dtype= np.float64) # int는 tensor에 없음
y = data[:, -1]
#print(x)
#print(y)

onehot = OneHotEncoder(categories = 'auto')
y = onehot.fit_transform(y[:, np.newaxis]).toarray()
print(y)

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 123)

print(x_train.shape)
n_features = x_train.shape[1]
n_classes = y_train.shape[1]
print(n_features)
print(n_classes)

def create_newModel(input_dim, output_dim, out_nodes, n, model_name = 'model'):
    def create_model():
        model = Sequential(name = model_name)
        for _ in range(n):
            model.add(Dense(out_nodes, input_dim = input_dim, activation = 'relu'))
            
        model.add(Dense(output_dim, activation = 'softmax'))
        model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])
        return model
    return create_model
'''
models = [create_newModel(n_features, n_classes, 10, n, 'model_{}'.format(n)) for n in range(1, 4)]

history_dict = {}

for create_model in models:
    create_model().summary()
    model = create_model()
    
    print(type(x_train))
    print(type(y_train))
    print(x_train.dtype, ' ', y_train.dtype)
    
    historys = model.fit(x_train, y_train, batch_size = 10, epochs = 10, verbose = 2, validation_split = 0.3)
    score = model.evaluate(x_test, y_test, verbose = 2)
    print('test accuracy : ', score[1])
    history_dict[model.name] = [historys, model]
    
print(history_dict)
'''
# 가장 마지막것의 정확도가 좋아서 채택
create_model = create_newModel(n_features, n_classes, 10, 3)

estimator = KerasClassifier(build_fn = create_model, epochs = 10, batch_size = 20, verbose = 2)
scores = cross_val_score(estimator, x, y, cv = 2)
print('Accuracy : {:0.2f} (±{:0.2f})'.format(scores.mean(), scores.std()))

model = Sequential()
model.add(Dense(10, input_dim = n_features, activation = 'relu'))
model.add(Dense(10, activation = 'relu'))
model.add(Dense(10, activation = 'relu'))
model.add(Dense(3, activation = 'softmax'))

model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['acc'])
print(model.summary())

model.fit(x_train, y_train, epochs = 10, batch_size = 20, verbose = 2)
print('모델 검증 : ', model.evaluate(x_test, y_test))

print()
y_pred = np.argmax(model.predict(x_test), axis = 1)
print('pred : ', y_pred)
real_y = np.argmax(y_test, axis = 1).reshape(-1, 1)
print("실제 값 : ", real_y.ravel())
print("분류 실패 수 : ", (y_pred != real_y.ravel()).sum())

print()
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
print('confusion_matrix : ', confusion_matrix(real_y, y_pred))
print('accuracy : ', accuracy_score(real_y, y_pred))
print('classification_report : \n', classification_report(real_y, y_pred))

# 새로운 값으로 예측하기
a = float(input('새로운 값 입력 : '))
new_data = [[]]


















