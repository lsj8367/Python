import tensorflow as tf
import numpy as np

# 선형회귀 모델 계산으로 작성
opti = tf.keras.optimizers.SGD()

w = tf.Variable(tf.random.normal((1,)))
b = tf.Variable(tf.random.normal((1,)))

def train_step(x, y):
    with tf.GradientTape() as tape:
        hypo = tf.add(tf.multiply(x, x), b)
        loss = tf.reduce_mean(tf.square(tf.subtract(hypo - y)))
    grad = tape.gradient(loss, [w, b]) # 미분
    opti.apply_gradients(zip(grad, [w, b]))
    return loss

x = [1., 2., 3., 4., 5.] # feature
y = [1.2, 2.0, 3.0, 3.5, 5.5] # label

w_val = []
loss_val = []
for i in range(100):
    loss_val = train_step(x, y)
    loss_val.append(loss_val.numpy())
    w_val.append(w.numpy())
    if i % 10 == 0:
        print(loss_val)

print(loss_val)
print(loss_val)








